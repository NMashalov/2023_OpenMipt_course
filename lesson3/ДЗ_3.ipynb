{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NMashalov/2023_OpenMipt_course/blob/main/lesson3/%D0%94%D0%97_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZP9LPFEREdl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-157QBwnV6i"
      },
      "source": [
        "# <a href=\"https://miptstats.github.io/courses/ad_mipt.html\">Phystech@DataScience</a>\n",
        "## Домашнее задание 3\n",
        "\n",
        "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
        "\n",
        "* Выполненную работу нужно отправить телеграм-боту `@miptstats_pds_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
        "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
        "* Прислать нужно ноутбук в формате `ipynb`.\n",
        "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
        "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
        "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
        "* Комментарии к решению пишите в markdown-ячейках.\n",
        "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
        "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
        "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
        "* **Код из рассказанных на занятиях ноутбуков можно использовать без ограничений.**\n",
        "\n",
        "**Правила оформления теоретических задач:**\n",
        "\n",
        "* Решения необходимо прислать одним из следующих способов:\n",
        "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
        "    * отправив ее как файл боту вместе с ноутбуком *или*\n",
        "    * вставив ее в ноутбук посредством `Edit -> Insert Image` (<font color=\"red\">фото, вставленные ссылкой, не принимаются</font>);\n",
        "  * в виде $\\LaTeX$ в markdown-ячейках.\n",
        "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
        "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
        "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
        "\n",
        "**Баллы за задание:**\n",
        "\n",
        "* Отрисовка изображений &mdash; 10 баллов\n",
        "* Построение сети ResNet &mdash; 80 баллов\n",
        "* Transfer Learning &mdash; 30 баллов\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1sxW4h3REdp"
      },
      "outputs": [],
      "source": [
        "# Bot check\n",
        "\n",
        "# HW_ID: phds_hw3\n",
        "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
        "\n",
        "# Status: not final\n",
        "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
        "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
        "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Nw2SbXFwBn"
      },
      "source": [
        "## Сверточные сети\n",
        "\n",
        "В этой домашней работе вам предстоит улучшить сверточную сеть для классификации изображений.\n",
        "\n",
        "#### Биология\n",
        "Необходимо классифицировать изображения МРТ головного мозга из датасета [**\"Brain Tumor Classification (MRI)\"**](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri) и определить вид опухоли.\n",
        "\n",
        "#### Физика\n",
        "Необходимо классифицировать изображения солнечного затмения из датасета [**\"Solar Eclipse Classification\"**](https://www.kaggle.com/datasets/tshr147/solar-eclipse-classification) по степени: частичное, полное и кольцевое."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y74GrmOYixMB"
      },
      "source": [
        "## Задача 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMi_1QOK3vQQ"
      },
      "source": [
        "**Пожалуйста, ПРОЧИТАЙТЕ ВНИМАТЕЛЬНО то, что написано ниже, там изложены требования к вашей работе и полезные советы!**\n",
        "\n",
        "\n",
        "**Требование к работе**\n",
        "\n",
        "* **Запрещено** использовать тестовые данные где-либо за исключением вычисления финальной оценки качества. Подсказка &mdash; распределение данных на тесте такое же как в тестовых данных.\n",
        "\n",
        "\n",
        "### Советы\n",
        "\n",
        "#### Архитектура нейросети\n",
        "* В отличие от семинара в данном датасете могут встретиться картинки разных размеров. Эту проблему можно решить двумя способами:\n",
        "  - Используя `torchvision.transforms.Resize` можно привести картинки к единому размеру. Если вы решите использовать этот способ, стоит посмотреть, какого в принципе размера встречаются картинки, чтобы не сжать их слишком сильно. Для картинок одного размера можно обучить бейзлайн в виде полносвязной сети.\n",
        "  - Учесть переменный размер картинки в архитектуре сети. Общий принцип здесь такой: можно использовать свертки с нужным `padding`, чтобы не иметь проблем из-за уменьшения размеров картинки из-за сверток, последовательно применяя сверточные слои и пуллинги, нужно увеличивать количество каналов одновременно с уменьшением размера картинок (из-за пуллинга), а в конце, получив картинку размера (n_channels, nx, ny), оставить вектор размера (n_channels) (n_channels будет одинаковым для всех картинок, поскольку зависит от архитектуры сети!). Сделать это можно усреднением по пространственным картам [torch.nn.AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html).\n",
        "* Попробуйте разные размеры фильтров, страйдинг, паддинг\n",
        "* Также можно попробовать разные активации: `tanh`, `leaky relu` и другие.\n",
        "\n",
        "#### Процесс обучения\n",
        "* Воспользуйтесь GPU google colab или любой другой GPU, которая у вас есть.\n",
        "* Для сокращения вычислительной сложности можно поэксперементировать с параметром `stride`. Кроме того можете попробовать разные виды Poooling-ов.\n",
        "* Помните, что некоторым нейросетям требуется $10$ эпох, чтобы сойтись, а некоторым – $500$. Большие нейросети дольше обучаются.\n",
        "* Если вы достигли какого-то порога на валидации лучше подождать примерно 10 эпох перед тем как останавливать обучение.\n",
        "\n",
        "#### И главное:\n",
        "* Рисуйте кривые обучения: loss и метрика качества (лучше использовать F1-меру) для обучения и валидации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH7VGEWk8Ix1",
        "outputId": "26a525ae-de9a-4538-a48f-84f44f90a75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "! pip install torchinfo\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NTJXij7G7uQj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.random import sample_without_replacement\n",
        "from IPython.display import Image, clear_output\n",
        "from collections import defaultdict\n",
        "from torch.optim import lr_scheduler\n",
        "from matplotlib.animation import FuncAnimation, ImageMagickFileWriter\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8yJKqChs9BF",
        "outputId": "de533528-5024-41f2-a6d5-5e82e7884b05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv kaggle.json /root/.kaggle/"
      ],
      "metadata": {
        "id": "ZJqYr7jJTZHW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sartajbhuvaji/brain-tumor-classification-mri\n",
        "!unzip brain-tumor-classification-mri.zip"
      ],
      "metadata": {
        "id": "ve2uKLGLS2ft",
        "outputId": "0dfc5395-6593-4fde-c9ec-b2c9ebd50234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading brain-tumor-classification-mri.zip to /content\n",
            " 84% 73.0M/86.8M [00:00<00:00, 136MB/s]\n",
            "100% 86.8M/86.8M [00:00<00:00, 126MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/'\n",
        "train_path = 'Training'\n",
        "test_path = 'Testing'"
      ],
      "metadata": {
        "id": "p2u1a_TfUACS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl2lXZZ0ixME"
      },
      "source": [
        "### Подготовка датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5IeBtzLT0I7i"
      },
      "outputs": [],
      "source": [
        "# Папка с изображениями для тренировки\n",
        "TRAIN_DIR = os.path.join(DATA_PATH, train_path)\n",
        "# Папка с изображениями для валидации\n",
        "VAL_DIR = os.path.join(DATA_PATH, \"val\")\n",
        "\n",
        "# Папка с изображениями для теста\n",
        "TEST_DIR = os.path.join(DATA_PATH, test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3glVY6H9pEEu",
        "outputId": "b41c93e7-fb51-4d55-9ace-3ed8e32acad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pituitary_tumor | train images = 579 | val images = 248\n",
            "no_tumor | train images = 277 | val images = 118\n",
            "glioma_tumor | train images = 579 | val images = 247\n",
            "meningioma_tumor | train images = 576 | val images = 246\n"
          ]
        }
      ],
      "source": [
        "! rm -rf $VAL_DIR\n",
        "os.makedirs(VAL_DIR, exist_ok=True)\n",
        "\n",
        "# Считываем названия директорий\n",
        "DIR_LIST = {i:name for i, name in enumerate(os.listdir(TRAIN_DIR))}\n",
        "# Доля изображений в валидации\n",
        "VAL_FRAC = 0.3\n",
        "\n",
        "# Создаем директорию с валидационной выборкой для каждого класса\n",
        "for dir in DIR_LIST.values():\n",
        "    os.makedirs(os.path.join(VAL_DIR, dir), exist_ok=True)\n",
        "\n",
        "    # Считываем выборку изображений\n",
        "    dir_path = os.path.join(TRAIN_DIR, dir)\n",
        "\n",
        "    # Сортируем изображения для детерминированнсти\n",
        "    images_filename = sorted(os.listdir(dir_path))\n",
        "\n",
        "    # Выбираем случайные изображения из выборки для валидции, с установленным random_state\n",
        "    num_images = len(images_filename)\n",
        "    num_val = int(num_images * VAL_FRAC)\n",
        "    indices = sample_without_replacement(num_images, num_val, random_state=42)\n",
        "    val_images = np.take(images_filename, indices)\n",
        "\n",
        "    print(f'{dir} | train images = {num_images - num_val} | val images = {num_val}')\n",
        "\n",
        "    # Сохраняем валидационную выборку\n",
        "    for image_filename in val_images:\n",
        "        source = os.path.join(TRAIN_DIR, dir, image_filename)\n",
        "        destination = os.path.join(VAL_DIR, dir, image_filename)\n",
        "        shutil.copy(source, destination)\n",
        "        os.remove(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G134scOxtJfH",
        "outputId": "4effbea7-7ee8-48e1-8b41-b404f3c74f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glioma_tumor  meningioma_tumor\tno_tumor  pituitary_tumor\n"
          ]
        }
      ],
      "source": [
        "!ls $TRAIN_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy9jvWXLi2QQ",
        "outputId": "e9c47b9c-316b-4b8d-c54f-185613c9a9bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glioma_tumor  meningioma_tumor\tno_tumor  pituitary_tumor\n"
          ]
        }
      ],
      "source": [
        "!ls $VAL_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nDirySpREdw"
      },
      "source": [
        "Отрисуйте по 3 изображения для каждого класса."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import v2\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    v2.RandomHorizontalFlip(p=0.5),\n",
        "    v2.ToImageTensor(),\n",
        "    v2.Grayscale(1),\n",
        "    v2.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    v2.ToImageTensor(),\n",
        "    v2.Grayscale(1),\n",
        "    v2.Normalize([0.5],[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "siwu80I6XBRF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
        "val_dataset = torchvision.datasets.ImageFolder(VAL_DIR, transform=val_transform)"
      ],
      "metadata": {
        "id": "bf1rH5OgW8fu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQqryd2SREdw"
      },
      "outputs": [],
      "source": [
        "#ваш код\n",
        "plt.figure(figsize=(30, 30))\n",
        "for\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsj2NrwqUn6q"
      },
      "source": [
        "### I. Построение сети ResNet\n",
        "\n",
        "В первой части задания вам предстоит имплементировать сеть ResNet.\n",
        "\n",
        "#### Архитектура сети\n",
        "\n",
        "<img src=\"https://github.com/NMashalov/2023_OpenMipt_course/blob/main/lesson3/resblock.png?raw=1\" width=\"400\" align=\"right\" >\n",
        "\n",
        "Артихектура сети выглядит следующим образом\n",
        "\n",
        "- В начале сети применяется сверточный слой с большим размером ядра (можно взять 5-7) и пулинг для уменьшения размерности входного изображения.\n",
        "- Далее следует какое-то количество ResidualBlock'ов. Блоки бывают двух типов: не меняющие пространственную и канальную размерности и сжимающие изображение одновременно с увеличением количества каналов. По мере продвижения в глубину сети количество каналов должно увеличиваться.\n",
        "- Перед предсказанием класса применяется Global Average Pooling для получения вектора фиксированной размерности, равной количеству каналов в конце сети.\n",
        "- Предсказание выполняется одним линейным слоем.\n",
        "\n",
        "Посмотрим как выглядит эффективный ResidualBlock, использованный в оригинальной статье\n",
        "\n",
        "\n",
        "1. Сначала применяется свертка 1х1 для уменьшения количества каналов (чтобы свертка с размером ядра 3 применялась к изображению с меньшим количеством каналов, т.е. работала быстрее и с меньшим количеством параметров)\n",
        "2. Далее делается основное преобразование: обычно это типичная последовательность действий `Conv -> BN -> Act`, не меняющая канальную размерность (она меняется при необходимости дальше из тех же соображений, что в п.1). В случае необходимости понизить пространственную размерность можно с помощью параметра `stride` у свертки.\n",
        "3. Далее с помощью свертки 1х1 изображение приводится к желаемому количеству каналов.\n",
        "4. В конце к выходу блока прибавляется вход (тот самый skip-connection). В случае если блок понижает пространственную размерность и повышает канальную, размерности исходного изображения и изображения после сверток не сходятся, поэтому перед сложением приходится применять дополнительное преобразование к исходной картинке. Его можно сделать с помощью все той же свертки 1х1 с параметром `stride`, соответствующим основному преобразованию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "599a7UYqixMG"
      },
      "source": [
        "#### Реализация сети\n",
        "\n",
        "В ходе реализации сети вам могут помочь следующие рекомендации\n",
        "\n",
        "Поскольку мы имеем дело с небольшими датасетами и небольшим количеством классов (и не собираемся доводить до 2048 каналов в конце), нет жесткой необходимости оптмизировать работу сверточных блоков. Вместо этого предлагается сделать менее эффективный, но более богатый параметрами блок. Можно использовать последовательность операций `Conv -> BN -> Act -> Conv -> BN` (перед сложением с \"входом\" блока лучше на ставить активацию), где одна из сверток выполняется со `stride=2`, если требуется. Также для облегчения обучения сети можно использовать свертку 1х1 (не забывайте нормализацию!) для преобразования входа, даже если увеличение количества каналов и уменьшение размерности не требуется.\n",
        "\n",
        "1. Реализуйте отдельно ResidualBlock. Убедитесь, что он работает, как ожидается, и в случае сохранения размера изображения, и в случае его изменения. Для удобства мы даем вам шаблон. Не забудьте использовать `padding`.\n",
        "2. Не забудьте сжать картинку перед применением ResidualBlock'ов с помощью свертки и пулинга. Степень сжатия зависит от размера вашего исходного изображения. Для размера изображения 256х256 можно попробовать сжать в 2-4 раза.\n",
        "3. Global Average Pooling реализован в PyTorch классом `nn.AdaptiveAvgPool2d`. Для использования в нашей сети его можно добавить после последнего сверточного слоя следующим образом `nn.AdaptiveAvgPool2d((1, 1))`.\n",
        "4. Вам не нужен ResNet50 :) Для проверки обучения начните с нескольких блоков, которые постепенно сжимают изображение - разжимают каналы в 2 раза. Тем не менее ваша сеть должна постепенно доводить канальную размерность не меньше, чем до 256 каналов.\n",
        "\n",
        "Для начала реализуйте блок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n2RQL4TTUzvO",
        "outputId": "d4ea7690-42a9-4fbe-d8f3-03ece7dbf508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4e2bac10bcd2>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    nn.ReLU(inplace=True),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "from torch.nn.modules.conv import ConvTranspose2d\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.inner_channels =  in_channels // 4\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # последовательность операций самого блока\n",
        "        self.blocks = nn.Sequential(\n",
        "            nn.Conv2d(self.in_channels, self.inner_channels, kernel_block=1),\n",
        "            nn.BatchNorm2d(self.inner_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2dself.inner_channel, self.inner_channel, kernel_block=stride,stride=stride), # сжимаем изображение в stride раз\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(self.inner_channel,self.out_channels)\n",
        "        )\n",
        "        # преобразование над входом до сложения с выходом\n",
        "        self.downsample = nn.Sequential(\n",
        "            nn.Conv2d(self.in_channels, self.out_channels, kernel_block=1),\n",
        "            nn.BatchNorm2d(self.inner_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxsRpghXlJem"
      },
      "source": [
        "Протестируйте блок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZlA0_rflMPz"
      },
      "outputs": [],
      "source": [
        "image_batch = torch.ones((3, 16, 67, 67))\n",
        "block1 = ResidualBlock(16, 16, 32, 1)\n",
        "assert block1(image_batch).shape == (3, 16, 67, 67), 'Блок не должен менять размер изображения'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKWTNoqSlvT8"
      },
      "outputs": [],
      "source": [
        "image_batch = torch.ones((3, 16, 64, 64))\n",
        "block1 = ResidualBlock(16, 32, 32, 2)\n",
        "assert block1(image_batch).shape == (3, 32, 32, 32), 'Блок должен сжать изображение в 2 раза и увеличить количество выходных каналов до 32'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sATOJIvqixMG"
      },
      "source": [
        "Реализуйте сеть целиком."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMXPgqPDixMG"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes, num_layers=None, layers_params=None):\n",
        "        \"\"\"\n",
        "        Класс реализующий сеть типа ResNet\n",
        "\n",
        "        param num_classes: количество классов, предсказываемых сетью\n",
        "        param num_layers: список количества блоков с параметрами layers_params, которые будут добавлены в сеть\n",
        "        param layers_params: список словарей параметров блоков\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # количество классов для классификации\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # дефолтные значения для примера\n",
        "        if num_layers is None:\n",
        "            num_layers = [1, 1, 1, 1, 1]\n",
        "        if layers_params is None:\n",
        "            layers_params = [\n",
        "                {\"in_channels\": 16, \"out_channels\": 32, \"stride\": 2},\n",
        "                {\"in_channels\": 32, \"out_channels\": 64, \"stride\": 2},\n",
        "                {\"in_channels\": 64, \"out_channels\": 64, \"stride\": 1},\n",
        "                {\"in_channels\": 64, \"out_channels\": 128, \"stride\": 2},\n",
        "                {\"in_channels\": 128, \"out_channels\": 128, \"stride\": 1}\n",
        "            ]\n",
        "\n",
        "        assert len(num_layers) == len(layers_params), 'Размеры списков, задающих параметры сети, должны быть одинаковы'\n",
        "\n",
        "        # Слои до residual блоков\n",
        "        self.preprocess = nn.Sequential()\n",
        "\n",
        "        # Задаем блоки с помощью num_layers и layers_params\n",
        "        self.residual_blocks = nn.Sequential()\n",
        "\n",
        "        # Голова сети\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        last_channels = # ваш код\n",
        "        self.fc = nn.Linear(last_channels, num_classes)\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HOteOuIREdz"
      },
      "source": [
        "Проверьте, что сеть работает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3jGCwLOrGRm"
      },
      "outputs": [],
      "source": [
        "resnet = ResNet(num_classes=4)\n",
        "image_batch = torch.ones((3, 3, 36, 36))\n",
        "resnet(image_batch).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8bzt_JrrquS"
      },
      "outputs": [],
      "source": [
        "image_batch = torch.ones((3, 3, 132, 177))\n",
        "resnet(image_batch).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZ5xRiwixMG"
      },
      "source": [
        "### Обучение сети\n",
        "\n",
        "**Важные советы:**\n",
        "\n",
        "1. Если сеть с дефолтным значением lr начнет слишком нестабильно учиться, уменьшите его.\n",
        "2. Используйте lr_scheduler для улучшения сходимости на более поздних итерациях. Можно, например, уменьшать lr в 2 раза после 3 эпох отсутствия улучшения метрики F1-macro.\n",
        "3. Используйте параметр `weight_decay`, если сеть будет склонна к переобучению. Начать можно со значения 0.1.\n",
        "4. Используйте аугментации для борьбы с переобучением. Отличный вариант - не слишком жесткие геометрические преобразования.\n",
        "\n",
        "\n",
        "Напишите функцию для обучения сети, куда можно передавать аугментации и lr_scheduler в качестве параметров. Используйте их для экспериментов. Также ваша функция должна в качестве параметра принимать директорию, куда будут сохраняться чекпойнты сети по ходу обучения (можете сохранять после каждой эпохи, а можете - только лучший по метрике F1-macro). Создать директорию из функции можно с помощью `os.makedirs(checkpoints_dir)`, а путь к чейкпойнту задавать с помощью `os.path.join(checkpoints_dir, f'epoch_{epoch}.checkpoint')` (для случая сохранения после каждой эпохи). Для сохранения сети используйте `torch.save(model.state_dict(), PATH)`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plYebeHjREd0"
      },
      "source": [
        "**Ваша задача:** добиться метрики F1-macro > 60% на тестовом наборе. Опишите свои эксперименты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv3WofffREeB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmts-a98sGCs"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4f6JD1gREeC"
      },
      "outputs": [],
      "source": [
        "# ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDwEAZPgREeC"
      },
      "source": [
        "### II. Transfer learning\n",
        "\n",
        "В этой части задания вам нужно зафайнтюнить предобученную модель, посчитать метрику на тестовом наборе и сравнить результат с предыдущем пунктом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atv0IvBhQTxl"
      },
      "outputs": [],
      "source": [
        "# ваш код"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}