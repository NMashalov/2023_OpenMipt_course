{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-157QBwnV6i"
      },
      "source": [
        "# <a href=\"https://miptstats.github.io/courses/ad_mipt.html\">Phystech@DataScience</a>\n",
        "## Домашнее задание 3\n",
        "\n",
        "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
        "\n",
        "* Выполненную работу нужно отправить телеграм-боту `@miptstats_pds_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
        "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
        "* Прислать нужно ноутбук в формате `ipynb`.\n",
        "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
        "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
        "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
        "* Комментарии к решению пишите в markdown-ячейках.\n",
        "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
        "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
        "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
        "* **Код из рассказанных на занятиях ноутбуков можно использовать без ограничений.**\n",
        "\n",
        "**Правила оформления теоретических задач:**\n",
        "\n",
        "* Решения необходимо прислать одним из следующих способов:\n",
        "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
        "    * отправив ее как файл боту вместе с ноутбуком *или*\n",
        "    * вставив ее в ноутбук посредством `Edit -> Insert Image` (<font color=\"red\">фото, вставленные ссылкой, не принимаются</font>);\n",
        "  * в виде $\\LaTeX$ в markdown-ячейках.\n",
        "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
        "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
        "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
        "\n",
        "**Баллы за задание:**\n",
        "\n",
        "* Отрисовка изображений &mdash; 10 баллов\n",
        "* Построение сети ResNet &mdash; 80 баллов\n",
        "* Transfer Learning &mdash; 30 баллов\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bot check\n",
        "\n",
        "# HW_ID: phds_hw3\n",
        "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
        "\n",
        "# Status: not final\n",
        "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
        "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
        "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Nw2SbXFwBn"
      },
      "source": [
        "## Сверточные сети\n",
        "\n",
        "В этой домашней работе вам предстоит улучшить сверточную сеть для классификации изображений.\n",
        "\n",
        "#### Биология\n",
        "Необходимо классифицировать изображения МРТ головного мозга из датасета [**\"Brain Tumor Classification (MRI)\"**](https://www.kaggle.com/datasets/sartajbhuvaji/brain-tumor-classification-mri) и определить вид опухоли.\n",
        "\n",
        "#### Физика\n",
        "Необходимо классифицировать изображения солнечного затмения из датасета [**\"Solar Eclipse Classification\"**](https://www.kaggle.com/datasets/tshr147/solar-eclipse-classification) по степени: частичное, полное и кольцевое."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y74GrmOYixMB"
      },
      "source": [
        "## Задача 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMi_1QOK3vQQ"
      },
      "source": [
        "**Пожалуйста, ПРОЧИТАЙТЕ ВНИМАТЕЛЬНО то, что написано ниже, там изложены требования к вашей работе и полезные советы!**\n",
        "\n",
        "\n",
        "**Требование к работе**\n",
        "\n",
        "* **Запрещено** использовать тестовые данные где-либо за исключением вычисления финальной оценки качества. Подсказка &mdash; распределение данных на тесте такое же как в тестовых данных.\n",
        "\n",
        "\n",
        "### Советы\n",
        "\n",
        "#### Архитектура нейросети\n",
        "* В отличие от семинара в данном датасете могут встретиться картинки разных размеров. Эту проблему можно решить двумя способами:\n",
        "  - Используя `torchvision.transforms.Resize` можно привести картинки к единому размеру. Если вы решите использовать этот способ, стоит посмотреть, какого в принципе размера встречаются картинки, чтобы не сжать их слишком сильно. Для картинок одного размера можно обучить бейзлайн в виде полносвязной сети.\n",
        "  - Учесть переменный размер картинки в архитектуре сети. Общий принцип здесь такой: можно использовать свертки с нужным `padding`, чтобы не иметь проблем из-за уменьшения размеров картинки из-за сверток, последовательно применяя сверточные слои и пуллинги, нужно увеличивать количество каналов одновременно с уменьшением размера картинок (из-за пуллинга), а в конце, получив картинку размера (n_channels, nx, ny), оставить вектор размера (n_channels) (n_channels будет одинаковым для всех картинок, поскольку зависит от архитектуры сети!). Сделать это можно усреднением по пространственным картам [torch.nn.AdaptiveAvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html).\n",
        "* Попробуйте разные размеры фильтров, страйдинг, паддинг\n",
        "* Также можно попробовать разные активации: `tanh`, `leaky relu` и другие.\n",
        "\n",
        "#### Процесс обучения\n",
        "* Воспользуйтесь GPU google colab или любой другой GPU, которая у вас есть.\n",
        "* Для сокращения вычислительной сложности можно поэксперементировать с параметром `stride`. Кроме того можете попробовать разные виды Poooling-ов.\n",
        "* Помните, что некоторым нейросетям требуется $10$ эпох, чтобы сойтись, а некоторым – $500$. Большие нейросети дольше обучаются.\n",
        "* Если вы достигли какого-то порога на валидации лучше подождать примерно 10 эпох перед тем как останавливать обучение.\n",
        "\n",
        "#### И главное:\n",
        "* Рисуйте кривые обучения: loss и метрика качества (лучше использовать F1-меру) для обучения и валидации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH7VGEWk8Ix1",
        "outputId": "bd1bcf55-b65c-41ac-8a68-9a73b954bcbe"
      },
      "outputs": [],
      "source": [
        "! pip install torchinfo\n",
        "\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTJXij7G7uQj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.random import sample_without_replacement\n",
        "from IPython.display import Image, clear_output\n",
        "from collections import defaultdict\n",
        "from torch.optim import lr_scheduler\n",
        "from matplotlib.animation import FuncAnimation, ImageMagickFileWriter\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8yJKqChs9BF",
        "outputId": "b88f5213-a5e5-498c-eda8-04f39ef277d2"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEMQU_irscwg"
      },
      "source": [
        "### Для Google Colab\n",
        "Чтобы не грузить данные каждый раз в колаб при его отключении, а данные сюда грузятся небыстро, будет лучше всего поступить следующим образом.\n",
        "* Загрузите архив на диск.\n",
        "* Примонтируйте ваш диск к данному ноутбуку с помощью кода ниже\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0uMuxuzNhZH",
        "outputId": "f025adbe-1293-4580-e08e-6b1444fcac03"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waf-0tb1smtl"
      },
      "source": [
        "* В панели слева (\"Файлы\") откройте папку `drive/MyDrive/..` и найдите архив с файлом на диске\n",
        "* Кликните по файлу и нажмите на кнопку \"Скопировать путь\"\n",
        "\n",
        "Теперь вы можете обратиться к данным, используя скопированный путь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgFZbVvzstOQ"
      },
      "outputs": [],
      "source": [
        "# Путь до архива с данными (пример)\n",
        "ZIP_PATH = \"/home/e-latypova/workspace/archive_bio.zip\"\n",
        "# Путь для папки с данными (пример)\n",
        "DATA_PATH = \"/home/e-latypova/workspace/archive_bio\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnqPLqeKs0ZP"
      },
      "source": [
        "Разархивируем данные на диске."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYsiSwJQ4Tkc"
      },
      "outputs": [],
      "source": [
        "! rm -rf $DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeY4GLCas2_P",
        "outputId": "51c900e3-0d28-4fc8-db6e-28a2fdb5571e"
      },
      "outputs": [],
      "source": [
        "! unzip $ZIP_PATH -d  $DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrviTbhws_Gx",
        "outputId": "2ffb92e6-1bc4-4243-f076-4de5d12324d6"
      },
      "outputs": [],
      "source": [
        "! ls $DATA_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = os.popen(f'ls {DATA_PATH}', 'r').read()\n",
        "output = output.replace('\\x1b[34m', '')\n",
        "output = output.replace('\\x1b[m', '')\n",
        "test_path = output.split('\\n')[0]\n",
        "train_path = output.split('\\n')[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl2lXZZ0ixME"
      },
      "source": [
        "### Подготовка датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IeBtzLT0I7i"
      },
      "outputs": [],
      "source": [
        "# Папка с изображениями для тренировки\n",
        "TRAIN_DIR = os.path.join(DATA_PATH, train_path)\n",
        "# Папка с изображениями для валидации\n",
        "VAL_DIR = os.path.join(DATA_PATH, \"val\")\n",
        "\n",
        "# Папка с изображениями для теста\n",
        "TEST_DIR = os.path.join(DATA_PATH, test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3glVY6H9pEEu",
        "outputId": "8d87fc30-042e-4139-f53e-30e546bc1c57"
      },
      "outputs": [],
      "source": [
        "! rm -rf $VAL_DIR\n",
        "os.makedirs(VAL_DIR, exist_ok=True)\n",
        "\n",
        "# Считываем названия директорий\n",
        "DIR_LIST = {i:name for i, name in enumerate(os.listdir(TRAIN_DIR))}\n",
        "# Доля изображений в валидации\n",
        "VAL_FRAC = 0.3\n",
        "\n",
        "# Создаем директорию с валидационной выборкой для каждого класса\n",
        "for dir in DIR_LIST.values():\n",
        "    os.makedirs(os.path.join(VAL_DIR, dir), exist_ok=True)\n",
        "\n",
        "    # Считываем выборку изображений\n",
        "    dir_path = os.path.join(TRAIN_DIR, dir)\n",
        "\n",
        "    # Сортируем изображения для детерминированнсти\n",
        "    images_filename = sorted(os.listdir(dir_path))\n",
        "\n",
        "    # Выбираем случайные изображения из выборки для валидции, с установленным random_state\n",
        "    num_images = len(images_filename)\n",
        "    num_val = int(num_images * VAL_FRAC)\n",
        "    indices = sample_without_replacement(num_images, num_val, random_state=42)\n",
        "    val_images = np.take(images_filename, indices)\n",
        "\n",
        "    print(f'{dir} | train images = {num_images - num_val} | val images = {num_val}')\n",
        "\n",
        "    # Сохраняем валидационную выборку\n",
        "    for image_filename in val_images:\n",
        "        source = os.path.join(TRAIN_DIR, dir, image_filename)\n",
        "        destination = os.path.join(VAL_DIR, dir, image_filename)\n",
        "        shutil.copy(source, destination)\n",
        "        os.remove(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G134scOxtJfH",
        "outputId": "bd7e691b-e79a-4835-92cc-86c3c7c6380e"
      },
      "outputs": [],
      "source": [
        "!ls $TRAIN_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy9jvWXLi2QQ",
        "outputId": "e9c5bf9b-675d-403a-ad54-a11f64a77243"
      },
      "outputs": [],
      "source": [
        "!ls $VAL_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Отрисуйте по 3 изображения для каждого класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsj2NrwqUn6q"
      },
      "source": [
        "### I. Построение сети ResNet\n",
        "\n",
        "В первой части задания вам предстоит имплементировать сеть ResNet.\n",
        "\n",
        "#### Архитектура сети\n",
        "\n",
        "<img src=\"resblock.png\" width=\"400\" align=\"right\" >\n",
        "\n",
        "Артихектура сети выглядит следующим образом\n",
        "\n",
        "- В начале сети применяется сверточный слой с большим размером ядра (можно взять 5-7) и пулинг для уменьшения размерности входного изображения.\n",
        "- Далее следует какое-то количество ResidualBlock'ов. Блоки бывают двух типов: не меняющие пространственную и канальную размерности и сжимающие изображение одновременно с увеличением количества каналов. По мере продвижения в глубину сети количество каналов должно увеличиваться.\n",
        "- Перед предсказанием класса применяется Global Average Pooling для получения вектора фиксированной размерности, равной количеству каналов в конце сети.\n",
        "- Предсказание выполняется одним линейным слоем.\n",
        "\n",
        "Посмотрим как выглядит эффективный ResidualBlock, использованный в оригинальной статье\n",
        "\n",
        "\n",
        "1. Сначала применяется свертка 1х1 для уменьшения количества каналов (чтобы свертка с размером ядра 3 применялась к изображению с меньшим количеством каналов, т.е. работала быстрее и с меньшим количеством параметров)\n",
        "2. Далее делается основное преобразование: обычно это типичная последовательность действий `Conv -> BN -> Act`, не меняющая канальную размерность (она меняется при необходимости дальше из тех же соображений, что в п.1). В случае необходимости понизить пространственную размерность можно с помощью параметра `stride` у свертки.\n",
        "3. Далее с помощью свертки 1х1 изображение приводится к желаемому количеству каналов.\n",
        "4. В конце к выходу блока прибавляется вход (тот самый skip-connection). В случае если блок понижает пространственную размерность и повышает канальную, размерности исходного изображения и изображения после сверток не сходятся, поэтому перед сложением приходится применять дополнительное преобразование к исходной картинке. Его можно сделать с помощью все той же свертки 1х1 с параметром `stride`, соответствующим основному преобразованию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "599a7UYqixMG"
      },
      "source": [
        "#### Реализация сети\n",
        "\n",
        "В ходе реализации сети вам могут помочь следующие рекомендации\n",
        "\n",
        "Поскольку мы имеем дело с небольшими датасетами и небольшим количеством классов (и не собираемся доводить до 2048 каналов в конце), нет жесткой необходимости оптмизировать работу сверточных блоков. Вместо этого предлагается сделать менее эффективный, но более богатый параметрами блок. Можно использовать последовательность операций `Conv -> BN -> Act -> Conv -> BN` (перед сложением с \"входом\" блока лучше на ставить активацию), где одна из сверток выполняется со `stride=2`, если требуется. Также для облегчения обучения сети можно использовать свертку 1х1 (не забывайте нормализацию!) для преобразования входа, даже если увеличение количества каналов и уменьшение размерности не требуется.\n",
        "\n",
        "1. Реализуйте отдельно ResidualBlock. Убедитесь, что он работает, как ожидается, и в случае сохранения размера изображения, и в случае его изменения. Для удобства мы даем вам шаблон. Не забудьте использовать `padding`.\n",
        "2. Не забудьте сжать картинку перед применением ResidualBlock'ов с помощью свертки и пулинга. Степень сжатия зависит от размера вашего исходного изображения. Для размера изображения 256х256 можно попробовать сжать в 2-4 раза.\n",
        "3. Global Average Pooling реализован в PyTorch классом `nn.AdaptiveAvgPool2d`. Для использования в нашей сети его можно добавить после последнего сверточного слоя следующим образом `nn.AdaptiveAvgPool2d((1, 1))`.\n",
        "4. Вам не нужен ResNet50 :) Для проверки обучения начните с нескольких блоков, которые постепенно сжимают изображение - разжимают каналы в 2 раза. Тем не менее ваша сеть должна постепенно доводить канальную размерность не меньше, чем до 256 каналов.\n",
        "\n",
        "Для начала реализуйте блок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2RQL4TTUzvO"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # последовательность операций самого блока\n",
        "        self.blocks = nn.Sequential()\n",
        "        # преобразование над входом до сложения с выходом\n",
        "        self.downsample = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxsRpghXlJem"
      },
      "source": [
        "Протестируйте блок."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZlA0_rflMPz"
      },
      "outputs": [],
      "source": [
        "image_batch = torch.ones((3, 16, 67, 67))\n",
        "block1 = ResidualBlock(16, 16, 32, 1)\n",
        "assert block1(image_batch).shape == (3, 16, 67, 67), 'Блок не должен менять размер изображения'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKWTNoqSlvT8"
      },
      "outputs": [],
      "source": [
        "image_batch = torch.ones((3, 16, 64, 64))\n",
        "block1 = ResidualBlock(16, 32, 32, 2)\n",
        "assert block1(image_batch).shape == (3, 32, 32, 32), 'Блок должен сжать изображение в 2 раза и увеличить количество выходных каналов до 32'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sATOJIvqixMG"
      },
      "source": [
        "Реализуйте сеть целиком."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMXPgqPDixMG"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes, num_layers=None, layers_params=None):\n",
        "        \"\"\"\n",
        "        Класс реализующий сеть типа ResNet\n",
        "\n",
        "        param num_classes: количество классов, предсказываемых сетью\n",
        "        param num_layers: список количества блоков с параметрами layers_params, которые будут добавлены в сеть\n",
        "        param layers_params: список словарей параметров блоков\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # количество классов для классификации\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # дефолтные значения для примера\n",
        "        if num_layers is None:\n",
        "            num_layers = [1, 1, 1, 1, 1]\n",
        "        if layers_params is None:\n",
        "            layers_params = [\n",
        "                {\"in_channels\": 16, \"out_channels\": 32, \"stride\": 2},\n",
        "                {\"in_channels\": 32, \"out_channels\": 64, \"stride\": 2},\n",
        "                {\"in_channels\": 64, \"out_channels\": 64, \"stride\": 1},\n",
        "                {\"in_channels\": 64, \"out_channels\": 128, \"stride\": 2},\n",
        "                {\"in_channels\": 128, \"out_channels\": 128, \"stride\": 1}\n",
        "            ]\n",
        "        \n",
        "        assert len(num_layers) == len(layers_params), 'Размеры списков, задающих параметры сети, должны быть одинаковы'\n",
        "\n",
        "        # Слои до residual блоков\n",
        "        self.preprocess = nn.Sequential()\n",
        "\n",
        "        # Задаем блоки с помощью num_layers и layers_params\n",
        "        self.residual_blocks = nn.Sequential()\n",
        "\n",
        "        # Голова сети\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        last_channels = # ваш код\n",
        "        self.fc = nn.Linear(last_channels, num_classes)\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Проверьте, что сеть работает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3jGCwLOrGRm",
        "outputId": "288e7802-8d95-44bf-e325-839271cce23e"
      },
      "outputs": [],
      "source": [
        "resnet = ResNet(num_classes=4)\n",
        "image_batch = torch.ones((3, 3, 36, 36))\n",
        "resnet(image_batch).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8bzt_JrrquS",
        "outputId": "ce678e5a-265c-4a7f-d686-021e4be8dc51"
      },
      "outputs": [],
      "source": [
        "image_batch = torch.ones((3, 3, 132, 177))\n",
        "resnet(image_batch).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZ5xRiwixMG"
      },
      "source": [
        "### Обучение сети\n",
        "\n",
        "**Важные советы:**\n",
        "\n",
        "1. Если сеть с дефолтным значением lr начнет слишком нестабильно учиться, уменьшите его.\n",
        "2. Используйте lr_scheduler для улучшения сходимости на более поздних итерациях. Можно, например, уменьшать lr в 2 раза после 3 эпох отсутствия улучшения метрики F1-macro.\n",
        "3. Используйте параметр `weight_decay`, если сеть будет склонна к переобучению. Начать можно со значения 0.1.\n",
        "4. Используйте аугментации для борьбы с переобучением. Отличный вариант - не слишком жесткие геометрические преобразования.\n",
        "\n",
        "\n",
        "Напишите функцию для обучения сети, куда можно передавать аугментации и lr_scheduler в качестве параметров. Используйте их для экспериментов. Также ваша функция должна в качестве параметра принимать директорию, куда будут сохраняться чекпойнты сети по ходу обучения (можете сохранять после каждой эпохи, а можете - только лучший по метрике F1-macro). Создать директорию из функции можно с помощью `os.makedirs(checkpoints_dir)`, а путь к чейкпойнту задавать с помощью `os.path.join(checkpoints_dir, f'epoch_{epoch}.checkpoint')` (для случая сохранения после каждой эпохи). Для сохранения сети используйте `torch.save(model.state_dict(), PATH)`. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Ваша задача:** добиться метрики F1-macro > 60% на тестовом наборе. Опишите свои эксперименты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmts-a98sGCs"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ваш код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### II. Transfer learning\n",
        "\n",
        "В этой части задания вам нужно зафайнтюнить предобученную модель, посчитать метрику на тестовом наборе и сравнить результат с предыдущем пунктом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atv0IvBhQTxl"
      },
      "outputs": [],
      "source": [
        "# ваш код"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
