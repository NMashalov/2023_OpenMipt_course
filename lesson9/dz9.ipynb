{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"https://miptstats.github.io/courses/ad_mipt.html\">Phystech@DataScience</a>\n",
    "## Домашнее задание 9\n",
    "\n",
    "**Правила, <font color=\"red\">прочитайте внимательно</font>:**\n",
    "\n",
    "* Выполненную работу нужно отправить телеграм-боту `@miptstats_pds_bot`. Для начала работы с ботом каждый раз отправляйте `/start`. **Работы, присланные иным способом, не принимаются.**\n",
    "* Дедлайн см. в боте. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Прислать нужно ноутбук в формате `ipynb`.\n",
    "* Выполнять задание необходимо полностью самостоятельно. **При обнаружении списывания все участники списывания будут сдавать устный зачет.**\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах, не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качестве основы, ничего не удаляя из него. Можно добавлять необходимое количество ячеек.\n",
    "* Комментарии к решению пишите в markdown-ячейках.\n",
    "* Выполнение задания (ход решения, выводы и пр.) должно быть осуществлено на русском языке.\n",
    "* Если код будет не понятен проверяющему, оценка может быть снижена.\n",
    "* Никакой код из данного задания при проверке запускаться не будет. *Если код студента не выполнен, недописан и т.д., то он не оценивается.*\n",
    "* **Код из рассказанных на занятиях ноутбуков можно использовать без ограничений.**\n",
    "\n",
    "**Правила оформления теоретических задач:**\n",
    "\n",
    "* Решения необходимо прислать одним из следующих способов:\n",
    "  * фотографией в правильной ориентации, где все четко видно, а почерк разборчив,\n",
    "    * отправив ее как файл боту вместе с ноутбуком *или*\n",
    "    * вставив ее в ноутбук посредством `Edit -> Insert Image` (<font color=\"red\">фото, вставленные ссылкой, не принимаются</font>);\n",
    "  * в виде $\\LaTeX$ в markdown-ячейках.\n",
    "* Решения не проверяются, если какое-то требование не выполнено. Особенно внимательно все проверьте в случае выбора второго пункта (вставки фото в ноутбук). <font color=\"red\"><b>Неправильно вставленные фотографии могут не передаться при отправке.</b></font> Для проверки попробуйте переместить `ipynb` в другую папку и открыть его там.\n",
    "* В решениях поясняйте, чем вы пользуетесь, хотя бы кратко. Например, если пользуетесь независимостью, то достаточно подписи вида \"*X и Y незав.*\"\n",
    "* Решение, в котором есть только ответ, и отсутствуют вычисления, оценивается в 0 баллов.\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "* Задача 1 &mdash;  40 баллов\n",
    "* Задача 2 &mdash;  30 баллов\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot check\n",
    "\n",
    "# HW_ID: phds_hw9\n",
    "# Бот проверит этот ID и предупредит, если случайно сдать что-то не то.\n",
    "\n",
    "# Status: not final\n",
    "# Перед отправкой в финальном решении удали \"not\" в строчке выше.\n",
    "# Так бот проверит, что ты отправляешь финальную версию, а не промежуточную.\n",
    "# Никакие значения в этой ячейке не влияют на факт сдачи работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as sps\n",
    "from warnings import filterwarnings\n",
    "from sklearn.neighbors import  NearestNeighbors\n",
    "\n",
    "\n",
    "from sklearn.cluster import \\\n",
    "    KMeans, \\\n",
    "    AgglomerativeClustering, \\\n",
    "    DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import sklearn.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим датасет [**Leaf Classification**](https://www.kaggle.com/c/leaf-classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные содержат 1584 изображений образцов листьев (16 изображений для 99 видов). Размер некоторых изображений изменен, в результате чего все изображения имеют одинаковый размер $170×250$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Скачайте файл с данными c вики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Загрузите все изображения с помощью `plt.imread` и визуализируйте некоторые из них. Каждое изображение — матрица размера $170×250$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 1584\n",
    "X = []\n",
    "\n",
    "for i in range(n_images):\n",
    "    new_img = plt.imread('scaled_images/' + str(i + 1) + '.jpg')\n",
    "    X.append(new_img)\n",
    "    \n",
    "X = np.array(X)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(X[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем также так, чтобы каждое изображение было представлено не матрицей, а одним вектором из всех пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = <...>\n",
    "assert(X.shape ==(1584, 42500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. В файле `train_labels.csv` указаны номера образцов листьев, которые относятся к обучающей части данных, а также их виды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('train_labels.csv')\n",
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите данные на обучающую и тестовую часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсортируем теперь по алфавиту названия видов и построим отображение строки в индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_names = sorted(np.unique(labels.species))\n",
    "name_to_ind = dict([(name, i) for (i, name) in enumerate(species_names)])\n",
    "labels.species = labels.species.map(name_to_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. На обучающей части данных постройте 30 главных компонент. Какую долю дисперсии данных они объясняют? Какую долю дисперсии объясняет каждая компонента отдельно? Постройте график доли объясненной дисперсии (зависимость доли от номера компоненты). Сделайте вывод.\n",
    "\n",
    "    * **Пояснение**: доля объясненной дисперсии - это показатель, характеризующий какую долю от общей дисперсии в данных объясняет данная компонента. Почитайте в документации метода главных компонент о `explained_variance_ratio_`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Визуализируйте главные компоненты: покажите, какие картинки из себя представляют главные компоненты. Для этого обратно перейдите обратно из представления изображения в виде одного длинного вектора к матрице. Можете ли вы их как-то охарактеризовать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Визуализируйте обучающую часть данных в проекции на две первых главных компоненты. Цвет точки должен соответствовать виду образца. Используйте `cmap=’Set1’` во избежание градации цвета по номеру вида. Наблюдаются ли какие-либо закономерности?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. По проекциям данных на первые 30 главных компонент обучите многоклассовую классификацию.\n",
    "\n",
    "    Используйте любую модель классификации, рассмотренную на нашем курсе.\n",
    "\n",
    "    Разделите данные на тренировочную и валидационную выборки и проверьте качество этой модели по метрике accuracy. Так как метки классов известны только для части данных, используйте только их. Сравните с результатом без применения PCA. Сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 \n",
    "Проведите свое исследование датасета из `data.txt` на кластеризацию изученными методами, реализованными в sklearn:\n",
    "\n",
    "- k-means;\n",
    "- DBSCAN;\n",
    "- Иерархическая кластеризация.\n",
    "\n",
    "Для каждого метода выше обоснуйте, почему выбранные вами гиперпараметры оптимальны, исходя из внутренней структуры данных. Если вы не можете применить какой-то из методов на этих данных, то обоснуйте, почему.\n",
    "\n",
    "*Примечание.* Задача является небольшим упражнением и не предполагает большое исследование.\n",
    "\n",
    "**Не забываем о предобработке данных!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<...>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
